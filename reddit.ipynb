{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here I build a model to classify reddit comments as positive or negative based on the content of each comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "from pyspark.sql.types import *\n",
    "from datetime import datetime\n",
    "from pyspark.sql import Row, functions as F\n",
    "from pyspark.ml.feature import Tokenizer, HashingTF, Binarizer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the Reddit data\n",
    "#### takes approximately 17 minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fields = [StructField(\"archived\", BooleanType(), True),\n",
    "        StructField(\"author\", StringType(), True),\n",
    "        StructField(\"author_flair_css_class\", StringType(), True),\n",
    "        StructField(\"body\", StringType(), True),\n",
    "        StructField(\"controversiality\", LongType(), True),\n",
    "        StructField(\"created_utc\", StringType(), True),\n",
    "        StructField(\"day\", LongType(), True),\n",
    "        StructField(\"distinguished\", StringType(), True),\n",
    "        StructField(\"downs\", LongType(), True),\n",
    "        StructField(\"edited\", StringType(), True),\n",
    "        StructField(\"gilded\", LongType(), True),\n",
    "        StructField(\"id\", StringType(), True),\n",
    "        StructField(\"link_id\", StringType(), True),\n",
    "        StructField(\"month\", LongType(), True),\n",
    "        StructField(\"name\", StringType(), True),\n",
    "        StructField(\"parent_id\", StringType(), True),\n",
    "        StructField(\"retrieved_on\", LongType(), True),\n",
    "        StructField(\"score\", LongType(), True),\n",
    "        StructField(\"score_hidden\", BooleanType(), True),\n",
    "        StructField(\"subreddit\", StringType(), True),\n",
    "        StructField(\"subreddit_id\", StringType(), True),\n",
    "        StructField(\"ups\", LongType(), True),\n",
    "        StructField(\"year\", LongType(), True)]\n",
    "\n",
    "rawDF = sqlContext.read.parquet(\"s3a://reddit-comments-parquet/year=2009\").persist(StorageLevel.MEMORY_AND_DISK_SER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rawDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## selecting the reddit.com subreddit comments here.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Select columns that are needed for the training and testing\n",
    "\n",
    "# Cast columns to the correct datatype for Transformers\n",
    "def cast_col(df, col, cast_type):\n",
    "    '''\n",
    "    Function to cast column into datatype for Transformers. \n",
    "    '''\n",
    "    return df.withColumn(\"temp_col\", df[col].cast(cast_type))\\\n",
    "             .drop(col)\\\n",
    "             .withColumnRenamed(\"temp_col\", col)\n",
    "\n",
    "# filter out comments with no score, comments that are deleted, and only use the reddit.com subreddit comments\n",
    "filteredDF = rawDF.select(\"id\", \"body\", \"score\", \"score_hidden\", \"subreddit\")\\\n",
    "                  .filter(rawDF.body != \"[deleted]\")\\\n",
    "                  .filter(rawDF.score_hidden == False)\\\n",
    "                  .filter(rawDF.subreddit == \"reddit.com\")\n",
    "castedDF = cast_col(filteredDF, \"score\", DoubleType())\n",
    "\n",
    "print \"Sample size: {}\".format(castedDF.count())\n",
    "\n",
    "castedDF.registerTempTable(\"rc\")\n",
    "\n",
    "query = sqlContext.sql(\"\"\"\n",
    "    SELECT score, COUNT(*) as cnt FROM rc\n",
    "    GROUP BY score\n",
    "    ORDER BY cnt DESC\n",
    "    \"\"\")\n",
    "result = query.toPandas()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the distribution of comment scores to see what the data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result.plot(x=\"score\", y=\"cnt\", kind=\"scatter\")\n",
    "plt.xlim([-20,20])\n",
    "plt.ylim([0, 800000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most comments have a score of 1, and the number of comments drops very rapidly on either side of this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a labeled dataset\n",
    "\n",
    "Since the majority of comments have a score of 0-3, I assume that a comment needs a score < 0 to be a negative comment and > 10 to be a positive comment (10% of the data falls into this classification scheme). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "negativeDF = castedDF.filter(castedDF[\"score\"] < 0)\n",
    "positiveDF = castedDF.filter(castedDF[\"score\"] > 10)\n",
    "\n",
    "print negativeDF.count(), positiveDF.count(), castedDF.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into training and testing data\n",
    "\n",
    "Combine the positive comments and negative comments, and randomly split them into training and testing datasets (80% in the training set, 20% in the testing set). \n",
    "\n",
    "I put the testing dataset aside for now and use the training dataset to train the model. Once the model is trained, I use the testing dataset to validate the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split dataset into training and testing\n",
    "mergedDF = negativeDF.unionAll(positiveDF)\n",
    "splitDF = mergedDF.randomSplit([0.8, 0.2])\n",
    "trainingDF = splitDF[0]\n",
    "testingDF = splitDF[1]\n",
    "\n",
    "trainingDF.persist(StorageLevel.MEMORY_AND_DISK)\n",
    "testingDF.persist(StorageLevel.MEMORY_AND_DISK)\n",
    "\n",
    "print \"training size: {}\".format(trainingDF.count())\n",
    "print \"negative sentiment: {}\".format(trainingDF.filter(trainingDF.score<0).count())\n",
    "print \"positive sentiment: {}\".format(trainingDF.filter(trainingDF.score>0).count())\n",
    "print \"testing size: {}\".format(testingDF.count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a model\n",
    "\n",
    "I use the frequency of each word in a comment as my features, other methods are: pyspark.ml.feature.IDF transformer, or removing stopwords.\n",
    "\n",
    "Build a ML pipeline by putting together the binarizer, tokenizer, hashingTF and logisticregression. In the end, I fit the model to the training dataset and make predictions on the testing dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create a column called 'label' that has converted the score into a column \n",
    "#that contains a 0 or 1, depending on the threshold variable\n",
    "binarizer = Binarizer(threshold=0.0, inputCol=\"score\", outputCol=\"label\")\n",
    "\n",
    "#tokenize the text into individual words\n",
    "tokenizer = Tokenizer(inputCol=\"body\", outputCol=\"words\")\n",
    "\n",
    "#calculate the term frequency and send the resulting values to a column called 'features'\n",
    "hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"features\")\n",
    "\n",
    "#maxIter is the maximum number of iterations completed when running the fit\n",
    "#regParam is the regularization strength\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.01)\n",
    "\n",
    "#put it all into a pipeline, fit on the training data, and test on the testing data!\n",
    "pipeline = Pipeline(stages=[binarizer, tokenizer, hashingTF, lr])\n",
    "model = pipeline.fit(trainingDF)\n",
    "prediction = model.transform(testingDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator() # area under the RoC curve\n",
    "train_RoC = evaluator.evaluate(model.transform(trainingDF))\n",
    "test_RoC = evaluator.evaluate(model.transform(testingDF))\n",
    "\n",
    "print \"The area under the RoC curve for the training set is {} and for the test set is {}\".format(train_RoC, test_RoC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check out the errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "selected = prediction.select(\"id\", \"body\", \"prediction\", \"label\")\n",
    "positive_score_rate = binarizer.transform(mergedDF).map(lambda r: r.label).mean()\n",
    "\n",
    "def typeI_II(row):\n",
    "    if row.prediction == 0 and row.label == 0:\n",
    "        return Row(error_type=\"true_neg\", cnt=1)\n",
    "    elif row.prediction == 0 and row.label == 1:\n",
    "        return Row(error_type=\"false_neg\", cnt=1)\n",
    "    elif row.prediction == 1 and row.label == 0:\n",
    "        return Row(error_type=\"false_pos\", cnt=1)\n",
    "    else:\n",
    "        return Row(error_type=\"true_pos\", cnt=1)\n",
    "\n",
    "typeI_II_DF = selected.map(lambda r: typeI_II(r)).toDF()\n",
    "type_error_pd = typeI_II_DF.groupBy(\"error_type\")\\\n",
    "                           .sum(\"cnt\")\\\n",
    "                           .withColumnRenamed(\"SUM(cnt)\", \"cnt\").toPandas()\n",
    "\n",
    "type_error_pd[\"tot\"] = type_error_pd[\"cnt\"].sum(axis=0)\n",
    "type_error_pd[\"perc\"] = type_error_pd[\"cnt\"]/type_error_pd[\"tot\"]\n",
    "print type_error_pd\n",
    "print \"percentage of comments with positive score in full set: {0:.2f}\".format(positive_score_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune the hyperparameters using grid search cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr_grid = LogisticRegression()\n",
    "pipeline = Pipeline(stages=[binarizer, tokenizer, hashingTF, lr_grid])\n",
    "\n",
    "grid = ParamGridBuilder()\\\n",
    "        .baseOn({lr_grid.labelCol: 'label'})\\\n",
    "        .addGrid(lr_grid.regParam, [0.01, 0.1])\\\n",
    "        .addGrid(lr_grid.elasticNetParam, [0.5,0.75])\\\n",
    "        .addGrid(lr_grid.maxIter, [1, 2])\\\n",
    "        .build()\n",
    "    \n",
    "evaluator = BinaryClassificationEvaluator() # the area under the RoC curve\n",
    "cv = CrossValidator(estimator=pipeline, estimatorParamMaps=grid, evaluator=evaluator, numFolds=4)\n",
    "cvModel = cv.fit(trainingDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print evaluator.evaluate(cvModel.transform(trainingDF))\n",
    "print evaluator.evaluate(cvModel.transform(testingDF))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
